{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0709085",
   "metadata": {},
   "source": [
    "## WEB SCRAPING – ASSIGNMENT 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf2b97",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos  \n",
    "### You need to find following details:\n",
    "- A) Rank\n",
    "- B) Name\n",
    "- C) Artist\n",
    "- D) Upload date\n",
    "- E) Views\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eba3ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cab42d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8bc984b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd31a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_top = driver.find_element(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/div[2]/ul/li[1]/a/span[2]')\n",
    "click_top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33648892",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_click = driver.find_element(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/div[2]/ul/li[1]/a/span[2]')\n",
    "top_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a6b446b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '\"Baby Shark Dance\"[4]',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " '11.74',\n",
       " 'June 17, 2016',\n",
       " '[A]',\n",
       " '2.',\n",
       " '\"Despacito\"[7]',\n",
       " 'Luis Fonsi',\n",
       " '8.01',\n",
       " 'January 12, 2017',\n",
       " '[B]',\n",
       " '3.',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " 'LooLoo Kids',\n",
       " '6.53',\n",
       " 'October 8, 2016',\n",
       " '[C]',\n",
       " '4.',\n",
       " '\"Shape of You\"[15]',\n",
       " 'Ed Sheeran',\n",
       " '5.85',\n",
       " 'January 30, 2017',\n",
       " '[D]',\n",
       " '5.',\n",
       " '\"Bath Song\"[17]',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " '5.77',\n",
       " 'May 2, 2018',\n",
       " '[E]',\n",
       " '6.',\n",
       " '\"See You Again\"[18]',\n",
       " 'Wiz Khalifa',\n",
       " '5.70',\n",
       " 'April 6, 2015',\n",
       " '[F]',\n",
       " '7.',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " 'ChuChu TV',\n",
       " '5.02',\n",
       " 'March 6, 2014',\n",
       " '[G]',\n",
       " '8.',\n",
       " '\"Uptown Funk\"[24]',\n",
       " 'Mark Ronson',\n",
       " '4.76',\n",
       " 'November 19, 2014',\n",
       " '[H]',\n",
       " '9.',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[25]',\n",
       " 'Miroshka TV',\n",
       " '4.73',\n",
       " 'February 27, 2018',\n",
       " '[I]',\n",
       " '10.',\n",
       " '\"Wheels on the Bus\"[26]',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " '4.63',\n",
       " 'May 24, 2018',\n",
       " '',\n",
       " '11.',\n",
       " '\"Gangnam Style\"[27]',\n",
       " 'Psy',\n",
       " '4.61',\n",
       " 'July 15, 2012',\n",
       " '[J]',\n",
       " '12.',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " 'Get Movies',\n",
       " '4.51',\n",
       " 'January 31, 2012',\n",
       " '[K]',\n",
       " '13.',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " 'El Chombo',\n",
       " '4.14',\n",
       " 'April 5, 2018',\n",
       " '',\n",
       " '14.',\n",
       " '\"Sugar\"[34]',\n",
       " 'Maroon 5',\n",
       " '3.78',\n",
       " 'January 14, 2015',\n",
       " '',\n",
       " '15.',\n",
       " '\"Roar\"[35]',\n",
       " 'Katy Perry',\n",
       " '3.69',\n",
       " 'September 5, 2013',\n",
       " '',\n",
       " '16.',\n",
       " '\"Counting Stars\"[36]',\n",
       " 'OneRepublic',\n",
       " '3.68',\n",
       " 'May 31, 2013',\n",
       " '',\n",
       " '17.',\n",
       " '\"Axel F\"[37]',\n",
       " 'Crazy Frog',\n",
       " '3.61',\n",
       " 'June 16, 2009',\n",
       " '',\n",
       " '18.',\n",
       " '\"Sorry\"[38]',\n",
       " 'Justin Bieber',\n",
       " '3.61',\n",
       " 'October 22, 2015',\n",
       " '',\n",
       " '19.',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " 'Ed Sheeran',\n",
       " '3.52',\n",
       " 'October 7, 2014',\n",
       " '',\n",
       " '20.',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " '3.43',\n",
       " 'June 25, 2018',\n",
       " '',\n",
       " '21.',\n",
       " '\"Dark Horse\"[41]',\n",
       " 'Katy Perry',\n",
       " '3.40',\n",
       " 'February 20, 2014',\n",
       " '',\n",
       " '22.',\n",
       " '\"Faded\"[42]',\n",
       " 'Alan Walker',\n",
       " '3.37',\n",
       " 'December 3, 2015',\n",
       " '',\n",
       " '23.',\n",
       " '\"Girls Like You\"[43]',\n",
       " 'Maroon 5',\n",
       " '3.35',\n",
       " 'May 31, 2018',\n",
       " '',\n",
       " '24.',\n",
       " '\"Let Her Go\"[44]',\n",
       " 'Passenger',\n",
       " '3.34',\n",
       " 'July 25, 2012',\n",
       " '',\n",
       " '25.',\n",
       " '\"Waka Waka (This Time for Africa)\"[45]',\n",
       " 'Shakira',\n",
       " '3.31',\n",
       " 'June 4, 2010',\n",
       " '',\n",
       " '26.',\n",
       " '\"Perfect\"[46]',\n",
       " 'Ed Sheeran',\n",
       " '3.30',\n",
       " 'November 9, 2017',\n",
       " '',\n",
       " '27.',\n",
       " '\"Bailando\"[47]',\n",
       " 'Enrique Iglesias',\n",
       " '3.30',\n",
       " 'April 11, 2014',\n",
       " '',\n",
       " '28.',\n",
       " '\"Lean On\"[48]',\n",
       " 'Major Lazer',\n",
       " '3.29',\n",
       " 'March 22, 2015',\n",
       " '',\n",
       " '29.',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " '3.23',\n",
       " 'January 26, 2018',\n",
       " '',\n",
       " '30.',\n",
       " '\"Shake It Off\"[50]',\n",
       " 'Taylor Swift',\n",
       " '3.23',\n",
       " 'August 18, 2014',\n",
       " '',\n",
       " '\"Baby Shark Dance\"[4]',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " '7,046,700,000',\n",
       " 'June 17, 2016',\n",
       " 'November 2, 2020',\n",
       " '1600',\n",
       " '761',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '\"Despacito\"[7]',\n",
       " 'Luis Fonsi',\n",
       " '2,993,700,000',\n",
       " 'January 12, 2017',\n",
       " 'August 4, 2017',\n",
       " '206',\n",
       " '1,186',\n",
       " '',\n",
       " '[62]',\n",
       " '[B]',\n",
       " '\"See You Again\"[18]',\n",
       " 'Wiz Khalifa',\n",
       " '2,894,000,000',\n",
       " 'April 6, 2015',\n",
       " 'July 10, 2017',\n",
       " '826',\n",
       " '25',\n",
       " '',\n",
       " '[19]',\n",
       " '',\n",
       " '\"Gangnam Style\"⁂[27]',\n",
       " 'Psy',\n",
       " '803,700,000',\n",
       " 'July 15, 2012',\n",
       " 'November 24, 2012',\n",
       " '134',\n",
       " '1,689',\n",
       " '',\n",
       " '[28]',\n",
       " '[J]',\n",
       " '\"Baby\"*[63]',\n",
       " 'Justin Bieber',\n",
       " '245,400,000',\n",
       " 'February 19, 2010',\n",
       " 'July 16, 2010',\n",
       " '149',\n",
       " '862',\n",
       " '',\n",
       " '[64]',\n",
       " '[L]',\n",
       " '\"Bad Romance\"[67]',\n",
       " 'Lady Gaga',\n",
       " '178,400,000',\n",
       " 'November 24, 2009',\n",
       " 'April 14, 2010',\n",
       " '143',\n",
       " '93',\n",
       " '',\n",
       " '[68]',\n",
       " '[M]',\n",
       " '\"Charlie Bit My Finger\"‡[71]',\n",
       " 'HDCYT',\n",
       " '128,900,000',\n",
       " 'May 22, 2007',\n",
       " 'October 25, 2009',\n",
       " '887',\n",
       " '171',\n",
       " 'late July 2021[72]',\n",
       " '[73]',\n",
       " '',\n",
       " '\"Evolution of Dance\"[74]',\n",
       " 'Judson Laipply',\n",
       " '118,900,000',\n",
       " 'April 6, 2006',\n",
       " 'May 2, 2009',\n",
       " '1062',\n",
       " '176',\n",
       " '',\n",
       " '[75]',\n",
       " '',\n",
       " '\"Girlfriend\"‡[76][77]',\n",
       " 'RCA Records',\n",
       " '92,600,000',\n",
       " 'February 27, 2007',\n",
       " 'July 17, 2008',\n",
       " '508',\n",
       " '289',\n",
       " 'no data',\n",
       " '[78]',\n",
       " '[N]',\n",
       " '\"Evolution of Dance\"[74]',\n",
       " 'Judson Laipply',\n",
       " '78,400,000',\n",
       " 'April 6, 2006',\n",
       " 'March 15, 2008',\n",
       " '651',\n",
       " '124',\n",
       " '',\n",
       " '[80]',\n",
       " '',\n",
       " '\"Music Is My Hot Hot Sex\"‡[81]',\n",
       " 'CLARUSBARTEL72',\n",
       " '76,600,000',\n",
       " 'April 9, 2007',\n",
       " 'March 1, 2008',\n",
       " '327',\n",
       " '14',\n",
       " 'mid-2008[82]',\n",
       " '[83]',\n",
       " '[O]',\n",
       " '\"Evolution of Dance\"*[74]',\n",
       " 'Judson Laipply',\n",
       " '10,600,000',\n",
       " 'April 6, 2006',\n",
       " 'May 19, 2006',\n",
       " '16',\n",
       " '652',\n",
       " '',\n",
       " '[86]',\n",
       " '[P]',\n",
       " '\"Pokémon Theme Music Video\"‡[87]',\n",
       " 'Smosh',\n",
       " '4,300,000',\n",
       " 'November 28, 2005',\n",
       " 'March 12, 2006',\n",
       " '105',\n",
       " '68',\n",
       " 'June 2007[88]',\n",
       " '[89]',\n",
       " '[Q]',\n",
       " '\"Myspace – The Movie\"‡[92][93]',\n",
       " 'eggtea',\n",
       " '2,700,000',\n",
       " 'January 31, 2006',\n",
       " 'February 18, 2006',\n",
       " '18',\n",
       " '22',\n",
       " 'mid-2006[94]',\n",
       " '[95]',\n",
       " '',\n",
       " '\"Phony Photo Booth\"‡[96]',\n",
       " 'mugenized',\n",
       " '3,400,000',\n",
       " 'December 1, 2005',\n",
       " 'January 21, 2006',\n",
       " '50',\n",
       " '28',\n",
       " 'no data',\n",
       " '[97]',\n",
       " '[R]',\n",
       " '\"The Chronic of Narnia Rap\"‡[98]',\n",
       " 'youtubedude',\n",
       " '2,300,000',\n",
       " 'December 18, 2005',\n",
       " 'January 9, 2006',\n",
       " '22',\n",
       " '12',\n",
       " 'no data',\n",
       " '[99]',\n",
       " '',\n",
       " '\"Ronaldinho: Touch of Gold\"‡*[100]',\n",
       " 'Nikesoccer',\n",
       " '255,000',\n",
       " 'October 21, 2005',\n",
       " 'October 31, 2005',\n",
       " '10',\n",
       " '70',\n",
       " 'no data',\n",
       " '[101]',\n",
       " '[S]',\n",
       " '\"I/O Brush\"‡*[103]',\n",
       " 'larfus',\n",
       " '247,000',\n",
       " 'October 5, 2005',\n",
       " 'October 29, 2005',\n",
       " '24',\n",
       " '2',\n",
       " 'no data',\n",
       " '[104]',\n",
       " '',\n",
       " '\"Me at the zoo\"[105]',\n",
       " 'jawed',\n",
       " '1',\n",
       " 'April 23, 2005',\n",
       " 'April 23, 2005',\n",
       " '0',\n",
       " '189',\n",
       " '',\n",
       " '[106]',\n",
       " '']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    details=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tbody//tr//td')\n",
    "\n",
    "    for i in details:\n",
    "\n",
    "        detail.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    detail.append('No details available')\n",
    "\n",
    "time.sleep(2) \n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fe39071",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = detail[0:180:6]\n",
    "video_name=detail[1:180:6]\n",
    "uploader=detail[2:180:6]\n",
    "upload_date=detail[4:180:6]\n",
    "views=detail[3:180:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e2513",
   "metadata": {},
   "source": [
    "## creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d9ac598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                         Uploader        Upload date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.74  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.01  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.53  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.85  \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   5.77  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.70  \n",
       "6                                       ChuChu TV      March 6, 2014   5.02  \n",
       "7                                     Mark Ronson  November 19, 2014   4.76  \n",
       "8                                     Miroshka TV  February 27, 2018   4.73  \n",
       "9                      Cocomelon – Nursery Rhymes       May 24, 2018   4.63  \n",
       "10                                            Psy      July 15, 2012   4.61  \n",
       "11                                     Get Movies   January 31, 2012   4.51  \n",
       "12                                      El Chombo      April 5, 2018   4.14  \n",
       "13                                       Maroon 5   January 14, 2015   3.78  \n",
       "14                                     Katy Perry  September 5, 2013   3.69  \n",
       "15                                    OneRepublic       May 31, 2013   3.68  \n",
       "16                                     Crazy Frog      June 16, 2009   3.61  \n",
       "17                                  Justin Bieber   October 22, 2015   3.61  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.52  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.43  \n",
       "20                                     Katy Perry  February 20, 2014   3.40  \n",
       "21                                    Alan Walker   December 3, 2015   3.37  \n",
       "22                                       Maroon 5       May 31, 2018   3.35  \n",
       "23                                      Passenger      July 25, 2012   3.34  \n",
       "24                                        Shakira       June 4, 2010   3.31  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.30  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.30  \n",
       "27                                    Major Lazer     March 22, 2015   3.29  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.23  \n",
       "29                                   Taylor Swift    August 18, 2014   3.23  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'Video name':video_name,'Uploader':uploader,'Upload date':upload_date,'Views':views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c735941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5412aad4",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "- A) Match title (I.e. 1st ODI)\n",
    "- B) Series\n",
    "- C) Place\n",
    "- D) Date\n",
    "- E) Time\n",
    "- Note: - From bcci.tv home page you have reach to the international fixture page through code.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27233a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98c089f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872a5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_button = driver.find_element(By.XPATH,'//button[@class=\"navbar-toggler menu-btn menu-icon collapsed\"]')\n",
    "menu_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dcaf684",
   "metadata": {},
   "outputs": [],
   "source": [
    "international_button = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "international_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5026993",
   "metadata": {},
   "source": [
    "### Extracting Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275ba01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INDIA A IN BANGLADESH MULTI DAY SERIES',\n",
       " 'NEW ZEALAND WM U19 IN INDIA T20 SERIES',\n",
       " 'INDIA TOUR OF BANGLADESH ODI SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH ODI SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022',\n",
       " 'INDIA TOUR OF BANGLADESH TEST SERIES 2022-23',\n",
       " 'AUSTRALIA WOMEN TOUR OF INDIA 2022']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = []\n",
    "series_tag = driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in series_tag:\n",
    "    series.append(i.text)\n",
    "series    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c231f",
   "metadata": {},
   "source": [
    "### Extracting Match Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5256cf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First-Class Match',\n",
       " \"Women's Youth T20 Match\",\n",
       " '2nd ODI',\n",
       " '1st T20I',\n",
       " '3rd ODI',\n",
       " '2nd T20I',\n",
       " '1st Test',\n",
       " '3rd T20I']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "title_tag = driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in title_tag:\n",
    "    title.append(i.text.split(' -')[0])\n",
    "title    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a831c1",
   "metadata": {},
   "source": [
    "### Extracting Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abc459f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Sylhet International Cricket Stadium, Sylhet',\n",
       " ' Sharad Pawar Cricket Academy BKC, Mumbai',\n",
       " ' Shere Bangla National Stadium, Mirpur, Dhaka',\n",
       " ' DY Patil Stadium, NAVI MUMBAI',\n",
       " ' Zahur Ahmed Chowdhury Stadium, Chattogram',\n",
       " ' DY Patil Stadium, NAVI MUMBAI',\n",
       " ' Zahur Ahmed Chowdhury Stadium, Chattogram',\n",
       " ' Brabourne']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = []\n",
    "place_tag = driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "for i in place_tag:\n",
    "    place.append(i.text.split(' -')[1])\n",
    "place    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe39475",
   "metadata": {},
   "source": [
    "### Extracting Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8ea3c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6 DEC 2022',\n",
       " '6 DEC 2022',\n",
       " '7 DEC 2022',\n",
       " '9 DEC 2022',\n",
       " '10 DEC 2022',\n",
       " '11 DEC 2022',\n",
       " '14 DEC 2022',\n",
       " '14 DEC 2022']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = []\n",
    "date_tag = driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for i in date_tag:\n",
    "    date.append(i.text)\n",
    "date    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af339205",
   "metadata": {},
   "source": [
    "### Extracting Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937497b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9:00 AM IST',\n",
       " '1:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '11:30 AM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 AM IST',\n",
       " '7:00 PM IST']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = []\n",
    "time_tag = driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "for i in time_tag:\n",
    "    time.append(i.text)\n",
    "time    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb804c0",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10e9e99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First-Class Match</td>\n",
       "      <td>INDIA A IN BANGLADESH MULTI DAY SERIES</td>\n",
       "      <td>Sylhet International Cricket Stadium, Sylhet</td>\n",
       "      <td>6 DEC 2022</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Youth T20 Match</td>\n",
       "      <td>NEW ZEALAND WM U19 IN INDIA T20 SERIES</td>\n",
       "      <td>Sharad Pawar Cricket Academy BKC, Mumbai</td>\n",
       "      <td>6 DEC 2022</td>\n",
       "      <td>1:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur, Dhaka</td>\n",
       "      <td>7 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>9 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium, Chattogram</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>DY Patil Stadium, NAVI MUMBAI</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>Zahur Ahmed Chowdhury Stadium, Chattogram</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>Brabourne</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Match Title                                        Series  \\\n",
       "0        First-Class Match        INDIA A IN BANGLADESH MULTI DAY SERIES   \n",
       "1  Women's Youth T20 Match        NEW ZEALAND WM U19 IN INDIA T20 SERIES   \n",
       "2                  2nd ODI   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "3                 1st T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "4                  3rd ODI   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   \n",
       "5                 2nd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "6                 1st Test  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   \n",
       "7                 3rd T20I            AUSTRALIA WOMEN TOUR OF INDIA 2022   \n",
       "\n",
       "                                           Place         Date          Time  \n",
       "0   Sylhet International Cricket Stadium, Sylhet   6 DEC 2022   9:00 AM IST  \n",
       "1       Sharad Pawar Cricket Academy BKC, Mumbai   6 DEC 2022   1:00 PM IST  \n",
       "2   Shere Bangla National Stadium, Mirpur, Dhaka   7 DEC 2022  11:30 AM IST  \n",
       "3                  DY Patil Stadium, NAVI MUMBAI   9 DEC 2022   7:00 PM IST  \n",
       "4      Zahur Ahmed Chowdhury Stadium, Chattogram  10 DEC 2022  11:30 AM IST  \n",
       "5                  DY Patil Stadium, NAVI MUMBAI  11 DEC 2022   7:00 PM IST  \n",
       "6      Zahur Ahmed Chowdhury Stadium, Chattogram  14 DEC 2022   9:30 AM IST  \n",
       "7                                      Brabourne  14 DEC 2022   7:00 PM IST  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Match Title':title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d19b363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ac084",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "- A) Name\n",
    "- B) Description\n",
    "- Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e70a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630fd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.guru99.com/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eb5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.XPATH,'//input[@class=\"gsc-input\"]')\n",
    "search_button.send_keys('selenium exception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9c71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button_click = driver.find_element(By.XPATH,'//button[@class=\"gsc-search-button gsc-search-button-v2\"]')\n",
    "search_button_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ec0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_hndling = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[1]/div[2]/div/div[1]/div/div/div/div[1]/div[6]/div[2]/div/div/div[1]/div[1]/div[1]/div[1]/div/a')\n",
    "exception_hndling.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f270c7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping exceptions names\n",
    "\n",
    "name=[]\n",
    "\n",
    "try:\n",
    "\n",
    "    names=driver.find_elements(By.XPATH,\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "    print(names)\n",
    "    for i in names[1:]:\n",
    "\n",
    "        name.append(i.text)\n",
    "\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "\n",
    "    name.append('No details available')\n",
    "\n",
    "time.sleep(2)   \n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdd674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "866dcea3",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "- A) Rank\n",
    "- B) State\n",
    "- C) GSDP(18-19)- at current prices\n",
    "- D) GSDP(19-20)- at current prices\n",
    "- E) Share(18-19)\n",
    "- F) GDP($ billion)\n",
    "- Note: - From statisticstimes home page you have to reach to economy page through code.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5b97355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed37f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://statisticstimes.com/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d43572ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy_button=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e290f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_states=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "indian_states.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de26396",
   "metadata": {},
   "source": [
    "### Etracting Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8a98891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "rank_tag = driver.find_elements(By.XPATH,'//td[@class=\"data1\"]')\n",
    "for i in rank_tag[0:33]:\n",
    "    rank.append(i.text)\n",
    "rank    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485b912",
   "metadata": {},
   "source": [
    "###  Extracting State\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "395d144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = []\n",
    "state_tag = driver.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for i in state_tag[0:33]:\n",
    "    state.append(i.text)\n",
    "state    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d971f082",
   "metadata": {},
   "source": [
    "### Extracting GSDP(18-19)- at current prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7be77eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp_cp=[]\n",
    "gsdp_cp_tag=driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')\n",
    "for i in gsdp_cp_tag[0:33]:\n",
    "    gsdp_cp.append(i.text)\n",
    "gsdp_cp    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c118296",
   "metadata": {},
   "source": [
    "### Extracting GSDP(19-20)- at current prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4be5fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GSDP_cp=[]\n",
    "GSDP_cp_tag=driver.find_elements(By.XPATH,'//td[@class=\"data\"]')\n",
    "for i in GSDP_cp_tag:\n",
    "    GSDP_cp.append(i.text)\n",
    "gsdp=GSDP_cp[0:162:5]  \n",
    "gsdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661d014",
   "metadata": {},
   "source": [
    "### Extracting Share(18-19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0ab1676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share=GSDP_cp[1:163:5]\n",
    "share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391b239",
   "metadata": {},
   "source": [
    "### Extracting GDP($ billion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "afe7c311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp=GSDP_cp[2:164:5]\n",
    "gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31957f75",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f01edaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20) - at current prices</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) - at current prices  \\\n",
       "0     1                Maharashtra                               -   \n",
       "1     2                 Tamil Nadu                       1,845,853   \n",
       "2     3              Uttar Pradesh                       1,687,818   \n",
       "3     4                    Gujarat                               -   \n",
       "4     5                  Karnataka                       1,631,977   \n",
       "5     6                West Bengal                       1,253,832   \n",
       "6     7                  Rajasthan                       1,020,989   \n",
       "7     8             Andhra Pradesh                         972,782   \n",
       "8     9                  Telangana                         969,604   \n",
       "9    10             Madhya Pradesh                         906,672   \n",
       "10   11                     Kerala                               -   \n",
       "11   12                      Delhi                         856,112   \n",
       "12   13                    Haryana                         831,610   \n",
       "13   14                      Bihar                         611,804   \n",
       "14   15                     Punjab                         574,760   \n",
       "15   16                     Odisha                         521,275   \n",
       "16   17                      Assam                               -   \n",
       "17   18               Chhattisgarh                         329,180   \n",
       "18   19                  Jharkhand                         328,598   \n",
       "19   20                Uttarakhand                               -   \n",
       "20   21            Jammu & Kashmir                               -   \n",
       "21   22           Himachal Pradesh                         165,472   \n",
       "22   23                        Goa                          80,449   \n",
       "23   24                    Tripura                          55,984   \n",
       "24   25                 Chandigarh                               -   \n",
       "25   26                 Puducherry                          38,253   \n",
       "26   27                  Meghalaya                          36,572   \n",
       "27   28                     Sikkim                          32,496   \n",
       "28   29                    Manipur                          31,790   \n",
       "29   30                   Nagaland                               -   \n",
       "30   31          Arunachal Pradesh                               -   \n",
       "31   32                    Mizoram                          26,503   \n",
       "32   33  Andaman & Nicobar Islands                               -   \n",
       "\n",
       "   GSDP(18-19)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                       2,632,792       13.94%        399.921  \n",
       "1                       1,630,208        8.63%        247.629  \n",
       "2                       1,584,764        8.39%        240.726  \n",
       "3                       1,502,899        7.96%        228.290  \n",
       "4                       1,493,127        7.91%        226.806  \n",
       "5                       1,089,898        5.77%        165.556  \n",
       "6                         942,586        4.99%        143.179  \n",
       "7                         862,957        4.57%        131.083  \n",
       "8                         861,031        4.56%        130.791  \n",
       "9                         809,592        4.29%        122.977  \n",
       "10                        781,653        4.14%        118.733  \n",
       "11                        774,870        4.10%        117.703  \n",
       "12                        734,163        3.89%        111.519  \n",
       "13                        530,363        2.81%         80.562  \n",
       "14                        526,376        2.79%         79.957  \n",
       "15                        487,805        2.58%         74.098  \n",
       "16                        315,881        1.67%         47.982  \n",
       "17                        304,063        1.61%         46.187  \n",
       "18                        297,204        1.57%         45.145  \n",
       "19                        245,895        1.30%         37.351  \n",
       "20                        155,956        0.83%         23.690  \n",
       "21                        153,845        0.81%         23.369  \n",
       "22                         73,170        0.39%         11.115  \n",
       "23                         49,845        0.26%          7.571  \n",
       "24                         42,114        0.22%          6.397  \n",
       "25                         34,433        0.18%          5.230  \n",
       "26                         33,481        0.18%          5.086  \n",
       "27                         28,723        0.15%          4.363  \n",
       "28                         27,870        0.15%          4.233  \n",
       "29                         27,283        0.14%          4.144  \n",
       "30                         24,603        0.13%          3.737  \n",
       "31                         22,287        0.12%          3.385  \n",
       "32                              -            -              -  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank,'State':state,'GSDP(19-20) - at current prices':gsdp,'GSDP(18-19)- at current prices':gsdp_cp,'Share(18-19)':share,'GDP($ billion)':gdp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f0d2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f7d44",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "- A) Repository title\n",
    "- B) Repository description\n",
    "- C) Contributors count\n",
    "- D) Language used\n",
    "- Note: - From the home page you have to click on the trending option from Explore menu through code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b53fb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "944a6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2a4fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_click = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "button_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ba0a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_click = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "trending_click.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7cb24",
   "metadata": {},
   "source": [
    "### Extracting Repository title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a426c0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['invoke-ai',\n",
       " 'apple',\n",
       " 'AleoHQ',\n",
       " 'misskey-dev',\n",
       " 'Klipper3d',\n",
       " 'PKUFlyingPig',\n",
       " 'danielgross',\n",
       " 'hehonghui',\n",
       " 'Visualize-ML',\n",
       " 'thangchung',\n",
       " 'monicahq',\n",
       " 'coolsnowwolf',\n",
       " 'Bogdanp',\n",
       " 'palera1n',\n",
       " 't3-oss',\n",
       " 'maplecool',\n",
       " 'openai',\n",
       " 'microsoft',\n",
       " 'evrone',\n",
       " 'openzfs',\n",
       " 'recloudstream',\n",
       " 'fspoettel',\n",
       " 'getify']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "title_tag=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]//a')\n",
    "for i in title_tag[0:23]:\n",
    "    title.append(i.text.split(' /')[0])\n",
    "\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1aedf",
   "metadata": {},
   "source": [
    "### Extracting Repository description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf6b7b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This version of Stable Diffusion features a slick WebGUI, an interactive command-line script that combines text2img and img2img functionality in a \"dream bot\" style interface, and multiple features and other enhancements. For more info, see the website link below.',\n",
       " 'Stable Diffusion with Core ML on Apple Silicon',\n",
       " 'A Decentralized Operating System for ZK Applications',\n",
       " '🌎 An interplanetary microblogging platform 🚀',\n",
       " 'Klipper is a 3d-printer firmware',\n",
       " '计算机自学指南',\n",
       " '经济学人(含音频)、纽约客、卫报、连线、大西洋月刊等英语杂志免费下载,支持epub、mobi、pdf格式, 每周更新',\n",
       " 'Book_4_《矩阵力量》 | 鸢尾花书：从加减乘除到机器学习；本册有，584幅图，81个代码文件，其中18个Streamlit App；状态：清华社五审五校中；Github稿件基本稳定，欢迎提意见，会及时修改',\n",
       " '☕ A practical event-driven microservices demo built with Golang. Nomad, Consul Connect, Vault, and Terraform for deployment',\n",
       " 'Personal CRM. Remember everything about your friends, family and business relationships.',\n",
       " \"Lean's LEDE source\",\n",
       " 'A collection of awesome resources related to the yearly Advent of Code challenge.',\n",
       " 'iOS 15.0-15.7.1 (semi-)tethered checkm8 \"jailbreak\"',\n",
       " 'The best way to start a full-stack, typesafe Next.js app',\n",
       " '世界上最简单的Trojan部署脚本，仅需一行命令即可搭建一台代理服务器',\n",
       " 'Node.js example app from the OpenAI API quickstart tutorial',\n",
       " 'Windows system utilities to maximize productivity',\n",
       " 'Clean Architecture template for Golang services',\n",
       " 'OpenZFS on Linux and FreeBSD',\n",
       " 'Android app for streaming and downloading Movies, TV-Series and Anime.',\n",
       " '🎄Starter template for solving Advent of Code in Rust.',\n",
       " 'A book series on JavaScript. @YDKJS on twitter.',\n",
       " 'Python example app from the OpenAI API quickstart tutorial']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = []\n",
    "desc_tag=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in desc_tag[0:23]:\n",
    "    desc.append(i.text)\n",
    "    \n",
    "desc    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a71910",
   "metadata": {},
   "source": [
    "### Extracting Contributors count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65d56afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['801',\n",
       " '102',\n",
       " '559',\n",
       " '490',\n",
       " '3,891',\n",
       " '2,726',\n",
       " '59',\n",
       " '192',\n",
       " '130',\n",
       " '162',\n",
       " '1,803',\n",
       " '18,387',\n",
       " '773',\n",
       " '157',\n",
       " '465',\n",
       " '42',\n",
       " '255',\n",
       " '4,740',\n",
       " '314',\n",
       " '1,541',\n",
       " '129',\n",
       " '9',\n",
       " '31,636']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = []\n",
    "try:\n",
    "    cont_tag=driver.find_elements(By.XPATH,'//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "    for i in cont_tag[1:47:2]:\n",
    "        cont.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    cont.append('-')\n",
    "    \n",
    "cont    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59580ca",
   "metadata": {},
   "source": [
    "### Extracting  Language \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "732bd775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jupyter Notebook',\n",
       " 'Python',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'C',\n",
       " 'HTML',\n",
       " 'Go',\n",
       " 'CSS',\n",
       " 'Python',\n",
       " 'Go',\n",
       " 'PHP',\n",
       " 'C',\n",
       " 'Shell',\n",
       " 'TypeScript',\n",
       " 'Shell',\n",
       " 'JavaScript',\n",
       " 'C#',\n",
       " 'Go',\n",
       " 'C',\n",
       " 'Kotlin',\n",
       " 'Rust',\n",
       " 'CSS',\n",
       " 'Rust']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = []\n",
    "try:\n",
    "    lang_tag=driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "    for i in lang_tag[0:23]:\n",
    "        lang.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    lang.append('-')\n",
    "    \n",
    "lang    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318da678",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a19654cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invoke-ai</td>\n",
       "      <td>This version of Stable Diffusion features a sl...</td>\n",
       "      <td>801</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>Stable Diffusion with Core ML on Apple Silicon</td>\n",
       "      <td>102</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AleoHQ</td>\n",
       "      <td>A Decentralized Operating System for ZK Applic...</td>\n",
       "      <td>559</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>misskey-dev</td>\n",
       "      <td>🌎 An interplanetary microblogging platform 🚀</td>\n",
       "      <td>490</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Klipper3d</td>\n",
       "      <td>Klipper is a 3d-printer firmware</td>\n",
       "      <td>3,891</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PKUFlyingPig</td>\n",
       "      <td>计算机自学指南</td>\n",
       "      <td>2,726</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>danielgross</td>\n",
       "      <td>经济学人(含音频)、纽约客、卫报、连线、大西洋月刊等英语杂志免费下载,支持epub、mobi...</td>\n",
       "      <td>59</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hehonghui</td>\n",
       "      <td>Book_4_《矩阵力量》 | 鸢尾花书：从加减乘除到机器学习；本册有，584幅图，81个代...</td>\n",
       "      <td>192</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visualize-ML</td>\n",
       "      <td>☕ A practical event-driven microservices demo ...</td>\n",
       "      <td>130</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thangchung</td>\n",
       "      <td>Personal CRM. Remember everything about your f...</td>\n",
       "      <td>162</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>monicahq</td>\n",
       "      <td>Lean's LEDE source</td>\n",
       "      <td>1,803</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>coolsnowwolf</td>\n",
       "      <td>A collection of awesome resources related to t...</td>\n",
       "      <td>18,387</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bogdanp</td>\n",
       "      <td>iOS 15.0-15.7.1 (semi-)tethered checkm8 \"jailb...</td>\n",
       "      <td>773</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>palera1n</td>\n",
       "      <td>The best way to start a full-stack, typesafe N...</td>\n",
       "      <td>157</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3-oss</td>\n",
       "      <td>世界上最简单的Trojan部署脚本，仅需一行命令即可搭建一台代理服务器</td>\n",
       "      <td>465</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>maplecool</td>\n",
       "      <td>Node.js example app from the OpenAI API quicks...</td>\n",
       "      <td>42</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>openai</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>255</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>microsoft</td>\n",
       "      <td>Clean Architecture template for Golang services</td>\n",
       "      <td>4,740</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>evrone</td>\n",
       "      <td>OpenZFS on Linux and FreeBSD</td>\n",
       "      <td>314</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>openzfs</td>\n",
       "      <td>Android app for streaming and downloading Movi...</td>\n",
       "      <td>1,541</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>recloudstream</td>\n",
       "      <td>🎄Starter template for solving Advent of Code i...</td>\n",
       "      <td>129</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fspoettel</td>\n",
       "      <td>A book series on JavaScript. @YDKJS on twitter.</td>\n",
       "      <td>9</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>getify</td>\n",
       "      <td>Python example app from the OpenAI API quickst...</td>\n",
       "      <td>31,636</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Repository title                             Repository description  \\\n",
       "0         invoke-ai  This version of Stable Diffusion features a sl...   \n",
       "1             apple     Stable Diffusion with Core ML on Apple Silicon   \n",
       "2            AleoHQ  A Decentralized Operating System for ZK Applic...   \n",
       "3       misskey-dev       🌎 An interplanetary microblogging platform 🚀   \n",
       "4         Klipper3d                   Klipper is a 3d-printer firmware   \n",
       "5      PKUFlyingPig                                            计算机自学指南   \n",
       "6       danielgross  经济学人(含音频)、纽约客、卫报、连线、大西洋月刊等英语杂志免费下载,支持epub、mobi...   \n",
       "7         hehonghui  Book_4_《矩阵力量》 | 鸢尾花书：从加减乘除到机器学习；本册有，584幅图，81个代...   \n",
       "8      Visualize-ML  ☕ A practical event-driven microservices demo ...   \n",
       "9        thangchung  Personal CRM. Remember everything about your f...   \n",
       "10         monicahq                                 Lean's LEDE source   \n",
       "11     coolsnowwolf  A collection of awesome resources related to t...   \n",
       "12          Bogdanp  iOS 15.0-15.7.1 (semi-)tethered checkm8 \"jailb...   \n",
       "13         palera1n  The best way to start a full-stack, typesafe N...   \n",
       "14           t3-oss                世界上最简单的Trojan部署脚本，仅需一行命令即可搭建一台代理服务器   \n",
       "15        maplecool  Node.js example app from the OpenAI API quicks...   \n",
       "16           openai  Windows system utilities to maximize productivity   \n",
       "17        microsoft    Clean Architecture template for Golang services   \n",
       "18           evrone                       OpenZFS on Linux and FreeBSD   \n",
       "19          openzfs  Android app for streaming and downloading Movi...   \n",
       "20    recloudstream  🎄Starter template for solving Advent of Code i...   \n",
       "21        fspoettel    A book series on JavaScript. @YDKJS on twitter.   \n",
       "22           getify  Python example app from the OpenAI API quickst...   \n",
       "\n",
       "   Contributors count     Language used  \n",
       "0                 801  Jupyter Notebook  \n",
       "1                 102            Python  \n",
       "2                 559              Rust  \n",
       "3                 490        TypeScript  \n",
       "4               3,891                 C  \n",
       "5               2,726              HTML  \n",
       "6                  59                Go  \n",
       "7                 192               CSS  \n",
       "8                 130            Python  \n",
       "9                 162                Go  \n",
       "10              1,803               PHP  \n",
       "11             18,387                 C  \n",
       "12                773             Shell  \n",
       "13                157        TypeScript  \n",
       "14                465             Shell  \n",
       "15                 42        JavaScript  \n",
       "16                255                C#  \n",
       "17              4,740                Go  \n",
       "18                314                 C  \n",
       "19              1,541            Kotlin  \n",
       "20                129              Rust  \n",
       "21                  9               CSS  \n",
       "22             31,636              Rust  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Repository title':title,'Repository description':desc,'Contributors count':cont,'Language used':lang})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b5d66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520d573",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "- A) Song name\n",
    "- B) Artist name\n",
    "- C) Last week rank\n",
    "- D) Peak rank\n",
    "- E) Weeks on board\n",
    "- Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a177810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ac33db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.billboard.com/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26932ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "charts = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f777bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_click= driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div[2]/div/div[1]/a/span/span')\n",
    "billboard_click.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2459e3d",
   "metadata": {},
   "source": [
    "### Extracting song name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c370f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "name_s= []\n",
    "name_s_tag = driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/h3')\n",
    "for i in name_s_tag:\n",
    "    name_s.append(i.text)    \n",
    "name_tag = driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)\n",
    "name  \n",
    "song_name = name_s + name\n",
    "len(song_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de31931",
   "metadata": {},
   "source": [
    "### Extracting Artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "65f85466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_name=[]\n",
    "name= []\n",
    "name_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)    \n",
    "a_name_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in a_name_tag:\n",
    "    a_name.append(i.text) \n",
    "artist_name = name+ a_name\n",
    "len(artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e49903",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_name=[]\n",
    "name= []\n",
    "name_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)    \n",
    "a_name_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "for i in a_name_tag:\n",
    "    a_name.append(i.text) \n",
    "artist_name = name+ a_name\n",
    "len(artist_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca69496",
   "metadata": {},
   "source": [
    "### Extracting last week rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e8b09a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "l_rank= []\n",
    "rank_tag = driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span')\n",
    "for i in rank_tag:\n",
    "    rank.append(i.text)    \n",
    "l_rank_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in l_rank_tag[0:594:6]:\n",
    "    l_rank.append(i.text) \n",
    "last_week_rank = rank+ l_rank\n",
    "len(last_week_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb24ad",
   "metadata": {},
   "source": [
    "### Extracting peak rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0563301b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=[]\n",
    "p_rank= []\n",
    "rank_tag = driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span') \n",
    "for i in rank_tag:\n",
    "    rank.append(i.text)       \n",
    "p_rank_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in p_rank_tag[1:594:6]:\n",
    "    p_rank.append(i.text) \n",
    "peak_rank = rank+ p_rank\n",
    "len(peak_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1702de",
   "metadata": {},
   "source": [
    "### Extracting weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "690f1fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week=[]\n",
    "week_b= []\n",
    "week_tag = driver.find_elements(By.XPATH,'/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span') \n",
    "for i in week_tag:\n",
    "    week.append(i.text)       \n",
    "week_b_tag = driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "for i in week_b_tag[2:594:6]:\n",
    "    week_b.append(i.text) \n",
    "week_on_board = week+ week_b\n",
    "len(week_on_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87e198",
   "metadata": {},
   "source": [
    "### create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "07cb6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rich Flex</td>\n",
       "      <td>Drake &amp; 21 Savage</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Die For You</td>\n",
       "      <td>Joji</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Down Home</td>\n",
       "      <td>Jimmie Allen</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Going, Going, Gone</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Middle Of The Ocean</td>\n",
       "      <td>Drake</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>More M’s</td>\n",
       "      <td>Drake &amp; 21 Savage</td>\n",
       "      <td>69</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song Name             Artist name Last Week Rank  \\\n",
       "0                         Anti-Hero            Taylor Swift              1   \n",
       "1                         Rich Flex       Drake & 21 Savage              2   \n",
       "2                            Unholy  Sam Smith & Kim Petras              3   \n",
       "3                         Bad Habit              Steve Lacy              4   \n",
       "4   All I Want For Christmas Is You            Mariah Carey             25   \n",
       "..                              ...                     ...            ...   \n",
       "95                      Die For You                    Joji             72   \n",
       "96                        Down Home            Jimmie Allen              -   \n",
       "97               Going, Going, Gone              Luke Combs             99   \n",
       "98              Middle Of The Ocean                   Drake             67   \n",
       "99                         More M’s       Drake & 21 Savage             69   \n",
       "\n",
       "   Peak Rank Week On Board  \n",
       "0          1             5  \n",
       "1          2             3  \n",
       "2          1             9  \n",
       "3          1            21  \n",
       "4          1            53  \n",
       "..       ...           ...  \n",
       "95        53             3  \n",
       "96        88             4  \n",
       "97        98             2  \n",
       "98        15             3  \n",
       "99        18             3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Song Name':song_name,'Artist name':artist_name,'Last Week Rank':last_week_rank,'Peak Rank':peak_rank,'Week On Board':week_on_board})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a6ff0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9033c52",
   "metadata": {},
   "source": [
    "### 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "- A) Name\n",
    "- B) Designation\n",
    "- C) Company\n",
    "- D) Skills they hire for\n",
    "- E) Location\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "082e4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cf15c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8b88a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "search_field.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5e6125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b69701b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "name_tag = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in name_tag:\n",
    "    name.append(i.text)\n",
    "len(name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701273c",
   "metadata": {},
   "source": [
    "### Extracting Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9a13854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = []\n",
    "comp_tag = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in comp_tag:\n",
    "    comp.append(i.text)\n",
    "len(comp)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afdfec",
   "metadata": {},
   "source": [
    "### Extracting skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "18349825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = []\n",
    "skill_tag = driver.find_elements(By.XPATH,'//div[@class=\"job-description fs12 grey-text\"]')\n",
    "for i in skill_tag:\n",
    "    skill.append(i.text)\n",
    "len(skill)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e066a",
   "metadata": {},
   "source": [
    "### Extracting Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "38e76ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = []\n",
    "loc_tag = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft fs12 lh16 locWdth\"]')\n",
    "for i in loc_tag:\n",
    "    loc.append(i.text)\n",
    "len(loc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0cb520",
   "metadata": {},
   "source": [
    "### Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "45849427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>- We are looking for passionate and skilled da...</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Requirements: Responsible for taking up day-to...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>You will be required to utilize the existing f...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Skill required: Data Science - Python Programm...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Lead - Forecasting</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Bachelor s degree in Computer science, Statist...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Preferred Educational Background PhD / Masters...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst - Data Science - Python/Machine Learni...</td>\n",
       "      <td>Huquo Consulting</td>\n",
       "      <td>BTech, MTech or MCA degree from a reputed univ...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deputy National Lead - Payments - Data Science</td>\n",
       "      <td>BAJAJ FINSERVE</td>\n",
       "      <td>Bachelor s Degree in computer science, Math, P...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist - Data Sciences</td>\n",
       "      <td>GEP</td>\n",
       "      <td>, code review and version control tools, batch...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Science, Need Immedia...</td>\n",
       "      <td>Citiustech</td>\n",
       "      <td>Work with OMICs, image, med device and RWE dat...</td>\n",
       "      <td>Hybrid - Pune, Gurgaon/Gurugram, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Technology Analyst / Data Science / Machine Le...</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>Bachelor of Engineering Good understanding of ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SR Program Manager Data Science 15 Yrs PLUS Fo...</td>\n",
       "      <td>Xpheno</td>\n",
       "      <td>Roles and Responsibilities Data Science Your P...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>The ideal candidate should have a strong clien...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Preferred Educational Background PhD / Masters...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hiring For Senior / Lead Data Scientist - Data...</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>A passion for writing high-quality code (Pytho...</td>\n",
       "      <td>Permanent Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Science - Statistical Analyses</td>\n",
       "      <td>Inspiration Manpower Consultancy</td>\n",
       "      <td>Skill required: Data Science - Statistical Ana...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Technical Experience : Experience in DevOps pr...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science Trainee</td>\n",
       "      <td>Medtoureasy</td>\n",
       "      <td>This program will help anyone interested in pu...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6 years of data science experience using stati...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>At least 2-3 years of experience of leading ju...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            JOB Title  \\\n",
       "0                  Data Science - Engineering Manager   \n",
       "1   ACN - Applied Intelligence - CC - Data Science...   \n",
       "2                                Analyst-Data Science   \n",
       "3                         Senior Analyst-Data Science   \n",
       "4                     Data Science Lead - Forecasting   \n",
       "5   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "6   Analyst - Data Science - Python/Machine Learni...   \n",
       "7      Deputy National Lead - Payments - Data Science   \n",
       "8                 Lead Data Scientist - Data Sciences   \n",
       "9   Assistant Manager - Data Science, Need Immedia...   \n",
       "10  Technology Analyst / Data Science / Machine Le...   \n",
       "11  SR Program Manager Data Science 15 Yrs PLUS Fo...   \n",
       "12  ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "13  ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "14  Hiring For Senior / Lead Data Scientist - Data...   \n",
       "15                Data Science - Statistical Analyses   \n",
       "16  Python Programming Language Data Science Pract...   \n",
       "17                               Data Science Trainee   \n",
       "18  ACN - Applied Intelligence - CC - Data Science...   \n",
       "19  ACN - Applied Intelligence - CC - Data Science...   \n",
       "\n",
       "                             Company  \\\n",
       "0                              Paytm   \n",
       "1                          Accenture   \n",
       "2                          Accenture   \n",
       "3                          Accenture   \n",
       "4                            Cargill   \n",
       "5                          Accenture   \n",
       "6                   Huquo Consulting   \n",
       "7                     BAJAJ FINSERVE   \n",
       "8                                GEP   \n",
       "9                         Citiustech   \n",
       "10                           Infosys   \n",
       "11                            Xpheno   \n",
       "12                         Accenture   \n",
       "13                         Accenture   \n",
       "14                   Tiger Analytics   \n",
       "15  Inspiration Manpower Consultancy   \n",
       "16                         Accenture   \n",
       "17                       Medtoureasy   \n",
       "18                         Accenture   \n",
       "19                         Accenture   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   - We are looking for passionate and skilled da...   \n",
       "1   Requirements: Responsible for taking up day-to...   \n",
       "2   You will be required to utilize the existing f...   \n",
       "3   Skill required: Data Science - Python Programm...   \n",
       "4   Bachelor s degree in Computer science, Statist...   \n",
       "5   Preferred Educational Background PhD / Masters...   \n",
       "6   BTech, MTech or MCA degree from a reputed univ...   \n",
       "7   Bachelor s Degree in computer science, Math, P...   \n",
       "8   , code review and version control tools, batch...   \n",
       "9   Work with OMICs, image, med device and RWE dat...   \n",
       "10  Bachelor of Engineering Good understanding of ...   \n",
       "11  Roles and Responsibilities Data Science Your P...   \n",
       "12  The ideal candidate should have a strong clien...   \n",
       "13  Preferred Educational Background PhD / Masters...   \n",
       "14  A passion for writing high-quality code (Pytho...   \n",
       "15  Skill required: Data Science - Statistical Ana...   \n",
       "16  Technical Experience : Experience in DevOps pr...   \n",
       "17  This program will help anyone interested in pu...   \n",
       "18  6 years of data science experience using stati...   \n",
       "19  At least 2-3 years of experience of leading ju...   \n",
       "\n",
       "                                             Location  \n",
       "0                      New Delhi, Bangalore/Bengaluru  \n",
       "1                                    Gurgaon/Gurugram  \n",
       "2                                 Bangalore/Bengaluru  \n",
       "3                                              Mumbai  \n",
       "4                                 Bangalore/Bengaluru  \n",
       "5                                    Gurgaon/Gurugram  \n",
       "6                                    Gurgaon/Gurugram  \n",
       "7                                                Pune  \n",
       "8                                              Remote  \n",
       "9   Hybrid - Pune, Gurgaon/Gurugram, Bangalore/Ben...  \n",
       "10                                Bangalore/Bengaluru  \n",
       "11                                Bangalore/Bengaluru  \n",
       "12                                Bangalore/Bengaluru  \n",
       "13                                Bangalore/Bengaluru  \n",
       "14                                   Permanent Remote  \n",
       "15            Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "16                                Bangalore/Bengaluru  \n",
       "17                                             Remote  \n",
       "18                                   Gurgaon/Gurugram  \n",
       "19                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'JOB Title':name,'Company':comp,'Skills':skill,'Location':loc})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cb979bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0046e",
   "metadata": {},
   "source": [
    "### 8. Scrape the details of Highest selling novels.\n",
    "url=https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "- A) Book name\n",
    "- B) Author name\n",
    "- C) Volumes sold\n",
    "- D) Publisher\n",
    "- E) Genre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "09dc19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6efc3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8d61676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Da Vinci Code,The',\n",
       " 'Brown, Dan',\n",
       " '5,094,805',\n",
       " 'Transworld',\n",
       " '2',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Rowling, J.K.',\n",
       " '4,475,152',\n",
       " 'Bloomsbury',\n",
       " '3',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Rowling, J.K.',\n",
       " '4,200,654',\n",
       " 'Bloomsbury',\n",
       " '4',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Rowling, J.K.',\n",
       " '4,179,479',\n",
       " 'Bloomsbury',\n",
       " '5',\n",
       " 'Fifty Shades of Grey',\n",
       " 'James, E. L.',\n",
       " '3,758,936',\n",
       " 'Random House',\n",
       " '6',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Rowling, J.K.',\n",
       " '3,583,215',\n",
       " 'Bloomsbury',\n",
       " '7',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Rowling, J.K.',\n",
       " '3,484,047',\n",
       " 'Bloomsbury',\n",
       " '8',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Rowling, J.K.',\n",
       " '3,377,906',\n",
       " 'Bloomsbury',\n",
       " '9',\n",
       " 'Angels and Demons',\n",
       " 'Brown, Dan',\n",
       " '3,193,946',\n",
       " 'Transworld',\n",
       " '10',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Rowling, J.K.',\n",
       " '2,950,264',\n",
       " 'Bloomsbury',\n",
       " '11',\n",
       " 'Fifty Shades Darker',\n",
       " 'James, E. L.',\n",
       " '2,479,784',\n",
       " 'Random House',\n",
       " '12',\n",
       " 'Twilight',\n",
       " 'Meyer, Stephenie',\n",
       " '2,315,405',\n",
       " 'Little, Brown Book',\n",
       " '13',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '2,233,570',\n",
       " 'Quercus',\n",
       " '14',\n",
       " 'Fifty Shades Freed',\n",
       " 'James, E. L.',\n",
       " '2,193,928',\n",
       " 'Random House',\n",
       " '15',\n",
       " 'Lost Symbol,The',\n",
       " 'Brown, Dan',\n",
       " '2,183,031',\n",
       " 'Transworld',\n",
       " '16',\n",
       " 'New Moon',\n",
       " 'Meyer, Stephenie',\n",
       " '2,152,737',\n",
       " 'Little, Brown Book',\n",
       " '17',\n",
       " 'Deception Point',\n",
       " 'Brown, Dan',\n",
       " '2,062,145',\n",
       " 'Transworld',\n",
       " '18',\n",
       " 'Eclipse',\n",
       " 'Meyer, Stephenie',\n",
       " '2,052,876',\n",
       " 'Little, Brown Book',\n",
       " '19',\n",
       " 'Lovely Bones,The',\n",
       " 'Sebold, Alice',\n",
       " '2,005,598',\n",
       " 'Pan Macmillan',\n",
       " '20',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Haddon, Mark',\n",
       " '1,979,552',\n",
       " 'Random House',\n",
       " '21',\n",
       " 'Digital Fortress',\n",
       " 'Brown, Dan',\n",
       " '1,928,900',\n",
       " 'Transworld',\n",
       " '22',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Bryson, Bill',\n",
       " '1,852,919',\n",
       " 'Transworld',\n",
       " '23',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '1,814,784',\n",
       " 'Quercus',\n",
       " '24',\n",
       " 'Breaking Dawn',\n",
       " 'Meyer, Stephenie',\n",
       " '1,787,118',\n",
       " 'Little, Brown Book',\n",
       " '25',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Carle, Eric',\n",
       " '1,783,535',\n",
       " 'Penguin',\n",
       " '26',\n",
       " 'Gruffalo,The',\n",
       " 'Donaldson, Julia',\n",
       " '1,781,269',\n",
       " 'Pan Macmillan',\n",
       " '27',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Oliver, Jamie',\n",
       " '1,743,266',\n",
       " 'Penguin',\n",
       " '28',\n",
       " 'Kite Runner,The',\n",
       " 'Hosseini, Khaled',\n",
       " '1,629,119',\n",
       " 'Bloomsbury',\n",
       " '29',\n",
       " 'One Day',\n",
       " 'Nicholls, David',\n",
       " '1,616,068',\n",
       " 'Hodder & Stoughton',\n",
       " '30',\n",
       " 'Thousand Splendid Suns,A',\n",
       " 'Hosseini, Khaled',\n",
       " '1,583,992',\n",
       " 'Bloomsbury',\n",
       " '31',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " 'Larsson, Stieg',\n",
       " '1,555,135',\n",
       " 'Quercus',\n",
       " '32',\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Niffenegger, Audrey',\n",
       " '1,546,886',\n",
       " 'Random House',\n",
       " '33',\n",
       " 'Atonement',\n",
       " 'McEwan, Ian',\n",
       " '1,539,428',\n",
       " 'Random House',\n",
       " '34',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'Fielding, Helen',\n",
       " '1,508,205',\n",
       " 'Pan Macmillan',\n",
       " '35',\n",
       " 'World According to Clarkson,The',\n",
       " 'Clarkson, Jeremy',\n",
       " '1,489,403',\n",
       " 'Penguin',\n",
       " '36',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Bernieres, Louis de',\n",
       " '1,352,318',\n",
       " 'Random House',\n",
       " '37',\n",
       " 'Sound of Laughter,The',\n",
       " 'Kay, Peter',\n",
       " '1,310,207',\n",
       " 'Random House',\n",
       " '38',\n",
       " 'Life of Pi',\n",
       " 'Martel, Yann',\n",
       " '1,310,176',\n",
       " 'Canongate',\n",
       " '39',\n",
       " 'Billy Connolly',\n",
       " 'Stephenson, Pamela',\n",
       " '1,231,957',\n",
       " 'HarperCollins',\n",
       " '40',\n",
       " 'Child Called It,A',\n",
       " 'Pelzer, Dave',\n",
       " '1,217,712',\n",
       " 'Orion',\n",
       " '41',\n",
       " \"Gruffalo's Child,The\",\n",
       " 'Donaldson, Julia',\n",
       " '1,208,711',\n",
       " 'Pan Macmillan',\n",
       " '42',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'McCourt, Frank',\n",
       " '1,204,058',\n",
       " 'HarperCollins',\n",
       " '43',\n",
       " 'Birdsong',\n",
       " 'Faulks, Sebastian',\n",
       " '1,184,967',\n",
       " 'Random House',\n",
       " '44',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,181,503',\n",
       " 'Scholastic Ltd.',\n",
       " '45',\n",
       " 'Labyrinth',\n",
       " 'Mosse, Kate',\n",
       " '1,181,093',\n",
       " 'Orion',\n",
       " '46',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Rowling, J.K.',\n",
       " '1,153,181',\n",
       " 'Bloomsbury',\n",
       " '47',\n",
       " 'Help,The',\n",
       " 'Stockett, Kathryn',\n",
       " '1,132,336',\n",
       " 'Penguin',\n",
       " '48',\n",
       " 'Man and Boy',\n",
       " 'Parsons, Tony',\n",
       " '1,130,802',\n",
       " 'HarperCollins',\n",
       " '49',\n",
       " 'Memoirs of a Geisha',\n",
       " 'Golden, Arthur',\n",
       " '1,126,337',\n",
       " 'Random House',\n",
       " '50',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'McCall Smith, Alexander',\n",
       " '1,115,549',\n",
       " 'Little, Brown Book',\n",
       " '51',\n",
       " 'Island,The',\n",
       " 'Hislop, Victoria',\n",
       " '1,108,328',\n",
       " 'Headline',\n",
       " '52',\n",
       " 'PS, I Love You',\n",
       " 'Ahern, Cecelia',\n",
       " '1,107,379',\n",
       " 'HarperCollins',\n",
       " '53',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'McKeith, Gillian',\n",
       " '1,104,403',\n",
       " 'Penguin',\n",
       " '54',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " '1,092,349',\n",
       " 'Orion',\n",
       " '55',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Rowling, J.K.',\n",
       " '1,090,847',\n",
       " 'Bloomsbury',\n",
       " '56',\n",
       " 'Broker,The',\n",
       " 'Grisham, John',\n",
       " '1,087,262',\n",
       " 'Random House',\n",
       " '57',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Atkins, Robert C.',\n",
       " '1,054,196',\n",
       " 'Random House',\n",
       " '58',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,037,160',\n",
       " 'Scholastic Ltd.',\n",
       " '59',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " 'Truss, Lynne',\n",
       " '1,023,688',\n",
       " 'Profile Books Group',\n",
       " '60',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Smith, Delia',\n",
       " '1,015,956',\n",
       " 'Random House',\n",
       " '61',\n",
       " 'Chocolat',\n",
       " 'Harris, Joanne',\n",
       " '1,009,873',\n",
       " 'Transworld',\n",
       " '62',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Boyne, John',\n",
       " '1,004,414',\n",
       " 'Random House Childrens Books G',\n",
       " '63',\n",
       " \"My Sister's Keeper\",\n",
       " 'Picoult, Jodi',\n",
       " '1,003,780',\n",
       " 'Hodder & Stoughton',\n",
       " '64',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,002,314',\n",
       " 'Scholastic Ltd.',\n",
       " '65',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Lee, Harper',\n",
       " '998,213',\n",
       " 'Random House',\n",
       " '66',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Gray, John',\n",
       " '992,846',\n",
       " 'HarperCollins',\n",
       " '67',\n",
       " 'Dear Fatty',\n",
       " 'French, Dawn',\n",
       " '986,753',\n",
       " 'Random House',\n",
       " '68',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lewycka, Marina',\n",
       " '986,115',\n",
       " 'Penguin',\n",
       " '69',\n",
       " 'Hannibal',\n",
       " 'Harris, Thomas',\n",
       " '970,509',\n",
       " 'Random House',\n",
       " '70',\n",
       " 'Lord of the Rings,The',\n",
       " 'Tolkien, J. R. R.',\n",
       " '967,466',\n",
       " 'HarperCollins',\n",
       " '71',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Moore, Michael',\n",
       " '963,353',\n",
       " 'Penguin',\n",
       " '72',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Rubenfeld, Jed',\n",
       " '962,515',\n",
       " 'Headline',\n",
       " '73',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Osbourne, Sharon',\n",
       " '959,496',\n",
       " 'Little, Brown Book',\n",
       " '74',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Coelho, Paulo',\n",
       " '956,114',\n",
       " 'HarperCollins',\n",
       " '75',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " \"O'Grady, Paul\",\n",
       " '945,640',\n",
       " 'Transworld',\n",
       " '76',\n",
       " 'Notes from a Small Island',\n",
       " 'Bryson, Bill',\n",
       " '931,312',\n",
       " 'Transworld',\n",
       " '77',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Oliver, Jamie',\n",
       " '925,425',\n",
       " 'Penguin',\n",
       " '78',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'Fielding, Helen',\n",
       " '924,695',\n",
       " 'Pan Macmillan',\n",
       " '79',\n",
       " \"Jamie's Italy\",\n",
       " 'Oliver, Jamie',\n",
       " '906,968',\n",
       " 'Penguin',\n",
       " '80',\n",
       " 'I Can Make You Thin',\n",
       " 'McKenna, Paul',\n",
       " '905,086',\n",
       " 'Transworld',\n",
       " '81',\n",
       " 'Down Under',\n",
       " 'Bryson, Bill',\n",
       " '890,847',\n",
       " 'Transworld',\n",
       " '82',\n",
       " 'Summons,The',\n",
       " 'Grisham, John',\n",
       " '869,671',\n",
       " 'Random House',\n",
       " '83',\n",
       " 'Small Island',\n",
       " 'Levy, Andrea',\n",
       " '869,659',\n",
       " 'Headline',\n",
       " '84',\n",
       " 'Nigella Express',\n",
       " 'Lawson, Nigella',\n",
       " '862,602',\n",
       " 'Random House',\n",
       " '85',\n",
       " 'Brick Lane',\n",
       " 'Ali, Monica',\n",
       " '856,540',\n",
       " 'Transworld',\n",
       " '86',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Edwards, Kim',\n",
       " '845,858',\n",
       " 'Penguin',\n",
       " '87',\n",
       " 'Room on the Broom',\n",
       " 'Donaldson, Julia',\n",
       " '842,535',\n",
       " 'Pan Macmillan',\n",
       " '88',\n",
       " 'About a Boy',\n",
       " 'Hornby, Nick',\n",
       " '828,215',\n",
       " 'Penguin',\n",
       " '89',\n",
       " 'My Booky Wook',\n",
       " 'Brand, Russell',\n",
       " '820,563',\n",
       " 'Hodder & Stoughton',\n",
       " '90',\n",
       " 'God Delusion,The',\n",
       " 'Dawkins, Richard',\n",
       " '816,907',\n",
       " 'Transworld',\n",
       " '91',\n",
       " '\"Beano\" Annual,The',\n",
       " '0',\n",
       " '816,585',\n",
       " 'D.C. Thomson',\n",
       " '92',\n",
       " 'White Teeth',\n",
       " 'Smith, Zadie',\n",
       " '815,586',\n",
       " 'Penguin',\n",
       " '93',\n",
       " 'House at Riverton,The',\n",
       " 'Morton, Kate',\n",
       " '814,370',\n",
       " 'Pan Macmillan',\n",
       " '94',\n",
       " 'Book Thief,The',\n",
       " 'Zusak, Markus',\n",
       " '809,641',\n",
       " 'Transworld',\n",
       " '95',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Binchy, Maeve',\n",
       " '808,900',\n",
       " 'Orion',\n",
       " '96',\n",
       " 'Ghost,The',\n",
       " 'Harris, Robert',\n",
       " '807,311',\n",
       " 'Random House',\n",
       " '97',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Oliver, Jamie',\n",
       " '794,201',\n",
       " 'Penguin',\n",
       " '98',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " 'Collins, Suzanne',\n",
       " '792,187',\n",
       " 'Scholastic Ltd.',\n",
       " '99',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " 'Pelzer, Dave',\n",
       " '791,507',\n",
       " 'Orion',\n",
       " '100',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\",\n",
       " 'Oliver, Jamie',\n",
       " '791,095',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "76bb713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = detail[0:500:5]\n",
    "book_name = detail[1:500:5]\n",
    "author_name=detail[2:500:5]\n",
    "vol_sales=detail[3:500:5]\n",
    "publisher = detail[4:500:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "00b1df56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag =driver.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "len(genre)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106166db",
   "metadata": {},
   "source": [
    "### creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5116f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Book Name       Author Name  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rank':rank,'Book Name':book_name,'Author Name':author_name,'Volume Sales':vol_sales,'Publisher':publisher,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8bb8d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8eb2c",
   "metadata": {},
   "source": [
    "### 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "- A) Name\n",
    "- B) Year span\n",
    "- C) Genre\n",
    "- D) Run time\n",
    "- E) Ratings\n",
    "- F) Votes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ece834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2d6af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af841af",
   "metadata": {},
   "source": [
    "### Extracting detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "635135eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a')\n",
    "for i in detail_tag:\n",
    "    detail.append(i.text)\n",
    "detail    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea8e8063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015–2021)',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = []\n",
    "year_tag = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year_tag:\n",
    "    year.append(i.text)\n",
    "year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf65bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.9',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "rating_tag = driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]')\n",
    "for i in rating_tag:\n",
    "    rating.append(i.text.split('\\n')[0])\n",
    "rating    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fe75b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = []\n",
    "run_tag = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in run_tag:\n",
    "    run.append(i.text)\n",
    "run    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7791b7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = []\n",
    "genre_tag = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in genre_tag:\n",
    "    genre.append(i.text)\n",
    "genre  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b241da84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,089,987',\n",
       " '1,179,545',\n",
       " '988,902',\n",
       " '292,860',\n",
       " '252,002',\n",
       " '302,913',\n",
       " '145,513',\n",
       " '308,898',\n",
       " '346,329',\n",
       " '431,982',\n",
       " '476,038',\n",
       " '807,139',\n",
       " '545,633',\n",
       " '924,256',\n",
       " '531,697',\n",
       " '168,032',\n",
       " '322,263',\n",
       " '319,636',\n",
       " '1,872,529',\n",
       " '324,406',\n",
       " '445,650',\n",
       " '535,313',\n",
       " '152,260',\n",
       " '148,927',\n",
       " '407,465',\n",
       " '225,433',\n",
       " '421,947',\n",
       " '440,823',\n",
       " '992,737',\n",
       " '683,122',\n",
       " '410,842',\n",
       " '387,683',\n",
       " '136,587',\n",
       " '124,424',\n",
       " '175,455',\n",
       " '155,001',\n",
       " '230,938',\n",
       " '504,958',\n",
       " '215,201',\n",
       " '430,616',\n",
       " '519,485',\n",
       " '64,108',\n",
       " '190,837',\n",
       " '504,633',\n",
       " '385,008',\n",
       " '79,627',\n",
       " '280,524',\n",
       " '243,374',\n",
       " '225,073',\n",
       " '217,659',\n",
       " '240,327',\n",
       " '725,412',\n",
       " '130,406',\n",
       " '339,899',\n",
       " '249,762',\n",
       " '553,471',\n",
       " '546,286',\n",
       " '464,883',\n",
       " '61,273',\n",
       " '111,548',\n",
       " '342,035',\n",
       " '74,405',\n",
       " '105,242',\n",
       " '237,038',\n",
       " '95,771',\n",
       " '95,504',\n",
       " '51,145',\n",
       " '148,994',\n",
       " '369,583',\n",
       " '316,108',\n",
       " '107,035',\n",
       " '248,239',\n",
       " '570,345',\n",
       " '105,443',\n",
       " '129,612',\n",
       " '525,192',\n",
       " '108,725',\n",
       " '236,533',\n",
       " '89,449',\n",
       " '22,874',\n",
       " '144,399',\n",
       " '160,675',\n",
       " '131,734',\n",
       " '37,601',\n",
       " '288,679',\n",
       " '120,482',\n",
       " '131,833',\n",
       " '74,326',\n",
       " '108,495',\n",
       " '199,570',\n",
       " '29,116',\n",
       " '185,723',\n",
       " '216,640',\n",
       " '748,520',\n",
       " '68,686',\n",
       " '50,184',\n",
       " '61,456',\n",
       " '198,326',\n",
       " '41,578',\n",
       " '245,226']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = []\n",
    "votes_tag = driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in votes_tag:\n",
    "    votes.append(i.text)\n",
    "votes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f108b5f",
   "metadata": {},
   "source": [
    "## Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ef8a5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,089,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,179,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>988,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>292,860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,089,987  \n",
       "1    51 min     8.7  1,179,545  \n",
       "2    44 min     8.1    988,902  \n",
       "3    60 min     7.5    292,860  \n",
       "4    43 min     7.6    252,002  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,184  \n",
       "96   50 min     7.8     61,456  \n",
       "97   42 min     8.1    198,326  \n",
       "98   45 min     7.1     41,578  \n",
       "99  572 min     8.6    245,226  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame({'Name':detail,'Year span':year,'Genre':genre,'Run time':run,'Ratings':rating,'Votes':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfe9d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413aef0f",
   "metadata": {},
   "source": [
    "### 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "- A) Dataset name\n",
    "- B) Data type\n",
    "- C) Task\n",
    "- D) Attribute type\n",
    "- E) No of instances\n",
    "- F) No of attribute\n",
    "- G) Year\n",
    "- Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4657f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time \n",
    "# import selenium webdriver\n",
    "from selenium import webdriver\n",
    "# importing required exceptions which need to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "# importing regex\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "085332e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d01129b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_all_dataset = driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "view_all_dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95a89f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abalone',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '4177 ',\n",
       " '8 ',\n",
       " '1995 ',\n",
       " 'Adult',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '48842 ',\n",
       " '14 ',\n",
       " '1996 ',\n",
       " 'Annealing',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '798 ',\n",
       " '38 ',\n",
       " ' ',\n",
       " 'Anonymous Microsoft Web Data',\n",
       " ' ',\n",
       " 'Recommender-Systems ',\n",
       " 'Categorical ',\n",
       " '37711 ',\n",
       " '294 ',\n",
       " '1998 ',\n",
       " 'Arrhythmia',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '452 ',\n",
       " '279 ',\n",
       " '1998 ',\n",
       " 'Artificial Characters',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '6000 ',\n",
       " '7 ',\n",
       " '1992 ',\n",
       " 'Audiology (Original)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '226 ',\n",
       " ' ',\n",
       " '1987 ',\n",
       " 'Audiology (Standardized)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '226 ',\n",
       " '69 ',\n",
       " '1992 ',\n",
       " 'Auto MPG',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Real ',\n",
       " '398 ',\n",
       " '8 ',\n",
       " '1993 ',\n",
       " 'Automobile',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '205 ',\n",
       " '26 ',\n",
       " '1987 ',\n",
       " 'Badges',\n",
       " 'Univariate, Text ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " '294 ',\n",
       " '1 ',\n",
       " '1994 ',\n",
       " 'Balance Scale',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '625 ',\n",
       " '4 ',\n",
       " '1994 ',\n",
       " 'Balloons',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '16 ',\n",
       " '4 ',\n",
       " ' ',\n",
       " 'Breast Cancer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '286 ',\n",
       " '9 ',\n",
       " '1988 ',\n",
       " 'Breast Cancer Wisconsin (Original)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '699 ',\n",
       " '10 ',\n",
       " '1992 ',\n",
       " 'Breast Cancer Wisconsin (Prognostic)',\n",
       " 'Multivariate ',\n",
       " 'Classification, Regression ',\n",
       " 'Real ',\n",
       " '198 ',\n",
       " '34 ',\n",
       " '1995 ',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '569 ',\n",
       " '32 ',\n",
       " '1995 ',\n",
       " 'Pittsburgh Bridges',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '108 ',\n",
       " '13 ',\n",
       " '1990 ',\n",
       " 'Car Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '1728 ',\n",
       " '6 ',\n",
       " '1997 ',\n",
       " 'Census Income',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '48842 ',\n",
       " '14 ',\n",
       " '1996 ',\n",
       " 'Chess (King-Rook vs. King-Knight)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " '22 ',\n",
       " '1988 ',\n",
       " 'Chess (King-Rook vs. King-Pawn)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '3196 ',\n",
       " '36 ',\n",
       " '1989 ',\n",
       " 'Chess (King-Rook vs. King)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '28056 ',\n",
       " '6 ',\n",
       " '1994 ',\n",
       " 'Chess (Domain Theories)',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Bach Chorales',\n",
       " 'Univariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '100 ',\n",
       " '6 ',\n",
       " ' ',\n",
       " 'Connect-4',\n",
       " 'Multivariate, Spatial ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '67557 ',\n",
       " '42 ',\n",
       " '1995 ',\n",
       " 'Credit Approval',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '690 ',\n",
       " '15 ',\n",
       " ' ',\n",
       " 'Japanese Credit Screening',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real, Integer ',\n",
       " '125 ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " 'Computer Hardware',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Integer ',\n",
       " '209 ',\n",
       " '9 ',\n",
       " '1987 ',\n",
       " 'Contraceptive Method Choice',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '1473 ',\n",
       " '9 ',\n",
       " '1997 ',\n",
       " 'Covertype',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '581012 ',\n",
       " '54 ',\n",
       " '1998 ',\n",
       " 'Cylinder Bands',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '512 ',\n",
       " '39 ',\n",
       " '1995 ',\n",
       " 'Dermatology',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '366 ',\n",
       " '33 ',\n",
       " '1998 ',\n",
       " 'Diabetes',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " ' ',\n",
       " '20 ',\n",
       " ' ',\n",
       " 'DGP2 - The Second Data Generation Program',\n",
       " 'Data-Generator ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Document Understanding',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " 'EBL Domain Theories',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Echocardiogram',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '132 ',\n",
       " '12 ',\n",
       " '1989 ',\n",
       " 'Ecoli',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '336 ',\n",
       " '8 ',\n",
       " '1996 ',\n",
       " 'Flags',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '194 ',\n",
       " '30 ',\n",
       " '1990 ',\n",
       " 'Function Finding',\n",
       " ' ',\n",
       " 'Function-Learning ',\n",
       " 'Real ',\n",
       " '352 ',\n",
       " ' ',\n",
       " '1990 ',\n",
       " 'Glass Identification',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '214 ',\n",
       " '10 ',\n",
       " '1987 ',\n",
       " \"Haberman's Survival\",\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '306 ',\n",
       " '3 ',\n",
       " '1999 ',\n",
       " 'Hayes-Roth',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '160 ',\n",
       " '5 ',\n",
       " '1989 ',\n",
       " 'Heart Disease',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '303 ',\n",
       " '75 ',\n",
       " '1988 ',\n",
       " 'Hepatitis',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '155 ',\n",
       " '19 ',\n",
       " '1988 ',\n",
       " 'Horse Colic',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '368 ',\n",
       " '27 ',\n",
       " '1989 ',\n",
       " 'ICU',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Image Segmentation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '2310 ',\n",
       " '19 ',\n",
       " '1990 ',\n",
       " 'Internet Advertisements',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '3279 ',\n",
       " '1558 ',\n",
       " '1998 ',\n",
       " 'Ionosphere',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '351 ',\n",
       " '34 ',\n",
       " '1989 ',\n",
       " 'Iris',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '150 ',\n",
       " '4 ',\n",
       " '1988 ',\n",
       " 'ISOLET',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '7797 ',\n",
       " '617 ',\n",
       " '1994 ',\n",
       " 'Kinship',\n",
       " 'Relational ',\n",
       " 'Relational-Learning ',\n",
       " 'Categorical ',\n",
       " '104 ',\n",
       " '12 ',\n",
       " '1990 ',\n",
       " 'Labor Relations',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '57 ',\n",
       " '16 ',\n",
       " '1988 ',\n",
       " 'LED Display Domain',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " ' ',\n",
       " '7 ',\n",
       " '1988 ',\n",
       " 'Lenses',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '24 ',\n",
       " '4 ',\n",
       " '1990 ',\n",
       " 'Letter Recognition',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '20000 ',\n",
       " '16 ',\n",
       " '1991 ',\n",
       " 'Liver Disorders',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '345 ',\n",
       " '7 ',\n",
       " '1990 ',\n",
       " 'Logic Theorist',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Lung Cancer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '32 ',\n",
       " '56 ',\n",
       " '1992 ',\n",
       " 'Lymphography',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '148 ',\n",
       " '18 ',\n",
       " '1988 ',\n",
       " 'Mechanical Analysis',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '209 ',\n",
       " '8 ',\n",
       " '1990 ',\n",
       " 'Meta-data',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '528 ',\n",
       " '22 ',\n",
       " '1996 ',\n",
       " 'Mobile Robots',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1995 ',\n",
       " 'Molecular Biology (Promoter Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '106 ',\n",
       " '58 ',\n",
       " '1990 ',\n",
       " 'Molecular Biology (Protein Secondary Structure)',\n",
       " 'Sequential ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '128 ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Molecular Biology (Splice-junction Gene Sequences)',\n",
       " 'Sequential, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '3190 ',\n",
       " '61 ',\n",
       " '1992 ',\n",
       " \"MONK's Problems\",\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '432 ',\n",
       " '7 ',\n",
       " '1992 ',\n",
       " 'Moral Reasoner',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " '202 ',\n",
       " ' ',\n",
       " '1994 ',\n",
       " 'Multiple Features',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '2000 ',\n",
       " '649 ',\n",
       " ' ',\n",
       " 'Mushroom',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '8124 ',\n",
       " '22 ',\n",
       " '1987 ',\n",
       " 'Musk (Version 1)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '476 ',\n",
       " '168 ',\n",
       " '1994 ',\n",
       " 'Musk (Version 2)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '6598 ',\n",
       " '168 ',\n",
       " '1994 ',\n",
       " 'Nursery',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '12960 ',\n",
       " '8 ',\n",
       " '1997 ',\n",
       " 'Othello Domain Theory',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1991 ',\n",
       " 'Page Blocks Classification',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '5473 ',\n",
       " '10 ',\n",
       " '1995 ',\n",
       " 'Optical Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '5620 ',\n",
       " '64 ',\n",
       " '1998 ',\n",
       " 'Pen-Based Recognition of Handwritten Digits',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '10992 ',\n",
       " '16 ',\n",
       " '1998 ',\n",
       " 'Post-Operative Patient',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '90 ',\n",
       " '8 ',\n",
       " '1993 ',\n",
       " 'Primary Tumor',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '339 ',\n",
       " '17 ',\n",
       " '1988 ',\n",
       " 'Prodigy',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Qualitative Structure Activity Relationships',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Quadruped Mammals',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " ' ',\n",
       " '72 ',\n",
       " '1992 ',\n",
       " 'Servo',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer ',\n",
       " '167 ',\n",
       " '4 ',\n",
       " '1993 ',\n",
       " 'Shuttle Landing Control',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '15 ',\n",
       " '6 ',\n",
       " '1988 ',\n",
       " 'Solar Flare',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical ',\n",
       " '1389 ',\n",
       " '10 ',\n",
       " '1989 ',\n",
       " 'Soybean (Large)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '307 ',\n",
       " '35 ',\n",
       " '1988 ',\n",
       " 'Soybean (Small)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '47 ',\n",
       " '35 ',\n",
       " '1987 ',\n",
       " 'Challenger USA Space Shuttle O-Ring',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Integer ',\n",
       " '23 ',\n",
       " '4 ',\n",
       " '1993 ',\n",
       " 'Low Resolution Spectrometer',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '531 ',\n",
       " '102 ',\n",
       " '1988 ',\n",
       " 'Spambase',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '4601 ',\n",
       " '57 ',\n",
       " '1999 ',\n",
       " 'SPECT Heart',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '267 ',\n",
       " '22 ',\n",
       " '2001 ',\n",
       " 'SPECTF Heart',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '267 ',\n",
       " '44 ',\n",
       " '2001 ',\n",
       " 'Sponge',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Categorical, Integer ',\n",
       " '76 ',\n",
       " '45 ',\n",
       " ' ',\n",
       " 'Statlog Project',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1992 ',\n",
       " 'Student Loan Relational',\n",
       " 'Domain-Theory ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1000 ',\n",
       " ' ',\n",
       " '1993 ',\n",
       " 'Teaching Assistant Evaluation',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '151 ',\n",
       " '5 ',\n",
       " '1997 ',\n",
       " 'Tic-Tac-Toe Endgame',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '958 ',\n",
       " '9 ',\n",
       " '1991 ',\n",
       " 'Thyroid Disease',\n",
       " 'Multivariate, Domain-Theory ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real ',\n",
       " '7200 ',\n",
       " '21 ',\n",
       " '1987 ',\n",
       " 'Trains',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '10 ',\n",
       " '32 ',\n",
       " '1994 ',\n",
       " 'University',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '285 ',\n",
       " '17 ',\n",
       " '1988 ',\n",
       " 'Congressional Voting Records',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '435 ',\n",
       " '16 ',\n",
       " '1987 ',\n",
       " 'Water Treatment Plant',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Integer, Real ',\n",
       " '527 ',\n",
       " '38 ',\n",
       " '1993 ',\n",
       " 'Waveform Database Generator (Version 1)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '5000 ',\n",
       " '21 ',\n",
       " '1988 ',\n",
       " 'Waveform Database Generator (Version 2)',\n",
       " 'Multivariate, Data-Generator ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '5000 ',\n",
       " '40 ',\n",
       " '1988 ',\n",
       " 'Wine',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Integer, Real ',\n",
       " '178 ',\n",
       " '13 ',\n",
       " '1991 ',\n",
       " 'Yeast',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '1484 ',\n",
       " '8 ',\n",
       " '1996 ',\n",
       " 'Zoo',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '101 ',\n",
       " '17 ',\n",
       " '1990 ',\n",
       " 'Undocumented',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Twenty Newsgroups',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " '20000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Australian Sign Language signs',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real ',\n",
       " '6650 ',\n",
       " '15 ',\n",
       " '1999 ',\n",
       " 'Australian Sign Language signs (High Quality)',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '2565 ',\n",
       " '22 ',\n",
       " '2002 ',\n",
       " 'US Census Data (1990)',\n",
       " 'Multivariate ',\n",
       " 'Clustering ',\n",
       " 'Categorical ',\n",
       " '2458285 ',\n",
       " '68 ',\n",
       " ' ',\n",
       " 'Census-Income (KDD)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '299285 ',\n",
       " '40 ',\n",
       " '2000 ',\n",
       " 'Coil 1999 Competition Data',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " '340 ',\n",
       " '17 ',\n",
       " '1999 ',\n",
       " 'Corel Image Features',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Real ',\n",
       " '68040 ',\n",
       " '89 ',\n",
       " '1999 ',\n",
       " 'E. Coli Genes',\n",
       " 'Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '2001 ',\n",
       " 'EEG Database',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '122 ',\n",
       " '4 ',\n",
       " '1999 ',\n",
       " 'El Nino',\n",
       " 'Spatio-temporal ',\n",
       " ' ',\n",
       " 'Integer, Real ',\n",
       " '178080 ',\n",
       " '12 ',\n",
       " '1999 ',\n",
       " 'Entree Chicago Recommendation Data',\n",
       " 'Transactional, Sequential ',\n",
       " 'Recommender-Systems ',\n",
       " 'Categorical ',\n",
       " '50672 ',\n",
       " ' ',\n",
       " '2000 ',\n",
       " 'CMU Face Images',\n",
       " 'Image ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '640 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Insurance Company Benchmark (COIL 2000)',\n",
       " 'Multivariate ',\n",
       " 'Regression, Description ',\n",
       " 'Categorical, Integer ',\n",
       " '9000 ',\n",
       " '86 ',\n",
       " '2000 ',\n",
       " 'Internet Usage Data',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '10104 ',\n",
       " '72 ',\n",
       " '1999 ',\n",
       " 'IPUMS Census Database',\n",
       " 'Multivariate ',\n",
       " ' ',\n",
       " 'Categorical, Integer ',\n",
       " '256932 ',\n",
       " '61 ',\n",
       " '1999 ',\n",
       " 'Japanese Vowels',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '640 ',\n",
       " '12 ',\n",
       " ' ',\n",
       " 'KDD Cup 1998 Data',\n",
       " 'Multivariate ',\n",
       " 'Regression ',\n",
       " 'Categorical, Integer ',\n",
       " '191779 ',\n",
       " '481 ',\n",
       " '1998 ',\n",
       " 'KDD Cup 1999 Data',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '4000000 ',\n",
       " '42 ',\n",
       " '1999 ',\n",
       " 'M. Tuberculosis Genes',\n",
       " 'Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '2001 ',\n",
       " 'Movie',\n",
       " 'Multivariate, Relational ',\n",
       " ' ',\n",
       " ' ',\n",
       " '10000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'MSNBC.com Anonymous Web Data',\n",
       " 'Sequential ',\n",
       " ' ',\n",
       " 'Categorical ',\n",
       " '989818 ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'NSF Research Award Abstracts 1990-2003',\n",
       " 'Text ',\n",
       " ' ',\n",
       " ' ',\n",
       " '129000 ',\n",
       " ' ',\n",
       " '2003 ',\n",
       " 'Pioneer-1 Mobile Robot Data',\n",
       " 'Multivariate, Time-Series ',\n",
       " ' ',\n",
       " 'Categorical, Real ',\n",
       " ' ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Pseudo Periodic Synthetic Time Series',\n",
       " 'Univariate, Time-Series ',\n",
       " ' ',\n",
       " ' ',\n",
       " '100000 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Reuters-21578 Text Categorization Collection',\n",
       " 'Text ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '21578 ',\n",
       " '5 ',\n",
       " '1997 ',\n",
       " 'Robot Execution Failures',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification ',\n",
       " 'Integer ',\n",
       " '463 ',\n",
       " '90 ',\n",
       " '1999 ',\n",
       " 'Synthetic Control Chart Time Series',\n",
       " 'Time-Series ',\n",
       " 'Classification, Clustering ',\n",
       " 'Real ',\n",
       " '600 ',\n",
       " ' ',\n",
       " '1999 ',\n",
       " 'Syskill and Webert Web Page Ratings',\n",
       " 'Multivariate, Text ',\n",
       " 'Classification ',\n",
       " 'Categorical ',\n",
       " '332 ',\n",
       " '5 ',\n",
       " '1998 ',\n",
       " 'UNIX User Data',\n",
       " 'Text, Sequential ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Volcanoes on Venus - JARtool experiment',\n",
       " 'Image ',\n",
       " 'Classification ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'Statlog (Australian Credit Approval)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer, Real ',\n",
       " '690 ',\n",
       " '14 ',\n",
       " ' ',\n",
       " 'Statlog (German Credit Data)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Integer ',\n",
       " '1000 ',\n",
       " '20 ',\n",
       " '1994 ',\n",
       " 'Statlog (Heart)',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Categorical, Real ',\n",
       " '270 ',\n",
       " '13 ',\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = []\n",
    "detail_tag = driver.find_elements(By.XPATH,'//p[@class=\"normal\"]')\n",
    "for i in detail_tag[8:4364]:\n",
    "    detail.append(i.text)\n",
    "detail    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffa4f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = detail[0:4364:7]\n",
    "datatype = detail[1:4364:7]\n",
    "task=detail[2:4364:7]\n",
    "attribute_type=detail[3:4364:7]\n",
    "instances = detail[4:4364:7]\n",
    "attributes = detail[5:4364:7]\n",
    "year=detail[6:4364:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdd7505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(datatype),len(task),len(attribute_type),len(instances),len(attributes),len(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11988d03",
   "metadata": {},
   "source": [
    "## Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0675d7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Datatype</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                       Datatype                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type Instances Attributes   Year  \n",
       "0    Categorical, Integer, Real      4177          8   1995   \n",
       "1          Categorical, Integer     48842         14   1996   \n",
       "2    Categorical, Integer, Real       798         38          \n",
       "3                   Categorical     37711        294   1998   \n",
       "4    Categorical, Integer, Real       452        279   1998   \n",
       "..                           ...       ...        ...    ...  \n",
       "617               Integer, Real     75840        525   2020   \n",
       "618               Integer, Real       400         50   2020   \n",
       "619                                  1014          7   2020   \n",
       "620                        Real     10129         16   2021   \n",
       "621                        Real      4000          2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Dataset Name':name,'Datatype':datatype,'Task':task,'Attribute Type':attribute_type,'Instances':instances,'Attributes':attributes,'Year':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bac737bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
